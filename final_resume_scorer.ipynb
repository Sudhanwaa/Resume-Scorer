{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pdf2image'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32md:\\Technolution_Assignmnet\\final_resume_scorer.ipynb Cell 1\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Technolution_Assignmnet/final_resume_scorer.ipynb#W0sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpytesseract\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Technolution_Assignmnet/final_resume_scorer.ipynb#W0sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mPIL\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Technolution_Assignmnet/final_resume_scorer.ipynb#W0sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpdf2image\u001b[39;00m \u001b[39mimport\u001b[39;00m convert_from_path\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Technolution_Assignmnet/final_resume_scorer.ipynb#W0sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mPyPDF2\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Technolution_Assignmnet/final_resume_scorer.ipynb#W0sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnltk\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pdf2image'"
     ]
    }
   ],
   "source": [
    "import pandas as  pd\n",
    "import pytesseract\n",
    "import PIL\n",
    "from pdf2image import convert_from_path\n",
    "import PyPDF2\n",
    "import nltk\n",
    "from nltk import word_tokenize, pos_tag\n",
    "import spacy\n",
    "import re\n",
    "from contractions import fix\n",
    "from nltk.corpus import stopwords\n",
    "import fitz \n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RUN THIS ONLY ONCE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sudha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sudha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\sudha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GIVE THE JOB DESCRIPTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_description='''Job Title: Machine Learning Engineer - NLP Specialist\n",
    "\n",
    "Location: Anytown, USA\n",
    "\n",
    "Company: Innovative Solutions Co.\n",
    "\n",
    "About Us:\n",
    "Innovative Solutions Co. is a cutting-edge technology company at the forefront of the artificial intelligence revolution. We specialize in developing intelligent systems that leverage Machine Learning, Deep Learning, and NLP to solve complex problems and enhance user experiences.\n",
    "\n",
    "Job Description:\n",
    "\n",
    "As a Machine Learning Engineer specializing in Natural Language Processing at Innovative Solutions Co., you will play a pivotal role in designing, developing, and deploying advanced NLP models and solutions. You will work in a collaborative and dynamic environment, pushing the boundaries of what's possible with AI technologies.\n",
    "\n",
    "Responsibilities:\n",
    "\n",
    "Research, design, and implement state-of-the-art NLP algorithms and models.\n",
    "Develop scalable and efficient solutions for language processing and understanding.\n",
    "Collaborate with cross-functional teams to integrate NLP capabilities into our products.\n",
    "Stay abreast of the latest advancements in NLP and machine learning research.\n",
    "Optimize and fine-tune existing models for improved performance.\n",
    "Work on real-world challenges in information retrieval, sentiment analysis, and language generation.\n",
    "Qualifications:\n",
    "\n",
    "Master's or Ph.D. in Computer Science, Machine Learning, or a related field.\n",
    "Solid foundation in machine learning and deep learning principles.\n",
    "Proven experience in developing and deploying NLP solutions.\n",
    "Proficiency in programming languages such as Python, TensorFlow, and PyTorch.\n",
    "Strong understanding of neural network architectures and attention mechanisms.\n",
    "Experience with large-scale data processing and distributed computing.\n",
    "Preferred Skills:\n",
    "\n",
    "Familiarity with cloud platforms (AWS, GCP, or Azure).\n",
    "Knowledge of containerization and orchestration tools (Docker, Kubernetes).\n",
    "Experience in building end-to-end ML pipelines.\n",
    "Strong problem-solving and critical-thinking skills.\n",
    "Excellent communication and collaboration abilities.\n",
    "Benefits:\n",
    "\n",
    "Competitive salary and performance-based bonuses.\n",
    "Comprehensive health, dental, and vision insurance.\n",
    "Flexible working hours and the option for remote work.\n",
    "Professional development opportunities and conference attendance.\n",
    "Collaborative and innovative work environment.\n",
    "If you are passionate about pushing the boundaries of NLP and are eager to contribute to groundbreaking projects, we invite you to join our team at Innovative Solutions Co. Apply today and be a part of shaping the future of artificial intelligence!'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEFINING THE TEXT CLEANING FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_lowercase(text):\n",
    "    lowercased_text = text.lower()\n",
    "    return lowercased_text\n",
    "\n",
    "def removing_stopwords(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "\n",
    "    # Remove stopwords\n",
    "    filtered_tokens = [word for word in tokens if word.lower() not in stopwords.words('english')]\n",
    "    return filtered_tokens\n",
    "\n",
    "def removing_special_characters(text):\n",
    "    # Check if text is None or not a string\n",
    "    if text is None or not isinstance(text, str):\n",
    "        return text  # Return input unchanged\n",
    "\n",
    "    # Use regex to remove special characters\n",
    "    cleaned_text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    return cleaned_text\n",
    "\n",
    "def lemmatization(text):\n",
    "    doc = nlp(text)\n",
    "\n",
    "    lemmatized_text = \" \".join([token.lemma_ for token in doc])\n",
    "    return lemmatized_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLEANING THE JOB DESCRIPTION CONTENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_description=removing_special_characters(job_description)\n",
    "job_description=to_lowercase(job_description)\n",
    "job_description=removing_stopwords(job_description)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['job',\n",
       " 'title',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'engineer',\n",
       " 'nlp',\n",
       " 'specialist',\n",
       " 'location',\n",
       " 'anytown',\n",
       " 'usa',\n",
       " 'company',\n",
       " 'innovative',\n",
       " 'solutions',\n",
       " 'co',\n",
       " 'us',\n",
       " 'innovative',\n",
       " 'solutions',\n",
       " 'co',\n",
       " 'cuttingedge',\n",
       " 'technology',\n",
       " 'company',\n",
       " 'forefront',\n",
       " 'artificial',\n",
       " 'intelligence',\n",
       " 'revolution',\n",
       " 'specialize',\n",
       " 'developing',\n",
       " 'intelligent',\n",
       " 'systems',\n",
       " 'leverage',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'deep',\n",
       " 'learning',\n",
       " 'nlp',\n",
       " 'solve',\n",
       " 'complex',\n",
       " 'problems',\n",
       " 'enhance',\n",
       " 'user',\n",
       " 'experiences',\n",
       " 'job',\n",
       " 'description',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'engineer',\n",
       " 'specializing',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " 'innovative',\n",
       " 'solutions',\n",
       " 'co',\n",
       " 'play',\n",
       " 'pivotal',\n",
       " 'role',\n",
       " 'designing',\n",
       " 'developing',\n",
       " 'deploying',\n",
       " 'advanced',\n",
       " 'nlp',\n",
       " 'models',\n",
       " 'solutions',\n",
       " 'work',\n",
       " 'collaborative',\n",
       " 'dynamic',\n",
       " 'environment',\n",
       " 'pushing',\n",
       " 'boundaries',\n",
       " 'whats',\n",
       " 'possible',\n",
       " 'ai',\n",
       " 'technologies',\n",
       " 'responsibilities',\n",
       " 'research',\n",
       " 'design',\n",
       " 'implement',\n",
       " 'stateoftheart',\n",
       " 'nlp',\n",
       " 'algorithms',\n",
       " 'models',\n",
       " 'develop',\n",
       " 'scalable',\n",
       " 'efficient',\n",
       " 'solutions',\n",
       " 'language',\n",
       " 'processing',\n",
       " 'understanding',\n",
       " 'collaborate',\n",
       " 'crossfunctional',\n",
       " 'teams',\n",
       " 'integrate',\n",
       " 'nlp',\n",
       " 'capabilities',\n",
       " 'products',\n",
       " 'stay',\n",
       " 'abreast',\n",
       " 'latest',\n",
       " 'advancements',\n",
       " 'nlp',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'research',\n",
       " 'optimize',\n",
       " 'finetune',\n",
       " 'existing',\n",
       " 'models',\n",
       " 'improved',\n",
       " 'performance',\n",
       " 'work',\n",
       " 'realworld',\n",
       " 'challenges',\n",
       " 'information',\n",
       " 'retrieval',\n",
       " 'sentiment',\n",
       " 'analysis',\n",
       " 'language',\n",
       " 'generation',\n",
       " 'qualifications',\n",
       " 'masters',\n",
       " 'phd',\n",
       " 'computer',\n",
       " 'science',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'related',\n",
       " 'field',\n",
       " 'solid',\n",
       " 'foundation',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'deep',\n",
       " 'learning',\n",
       " 'principles',\n",
       " 'proven',\n",
       " 'experience',\n",
       " 'developing',\n",
       " 'deploying',\n",
       " 'nlp',\n",
       " 'solutions',\n",
       " 'proficiency',\n",
       " 'programming',\n",
       " 'languages',\n",
       " 'python',\n",
       " 'tensorflow',\n",
       " 'pytorch',\n",
       " 'strong',\n",
       " 'understanding',\n",
       " 'neural',\n",
       " 'network',\n",
       " 'architectures',\n",
       " 'attention',\n",
       " 'mechanisms',\n",
       " 'experience',\n",
       " 'largescale',\n",
       " 'data',\n",
       " 'processing',\n",
       " 'distributed',\n",
       " 'computing',\n",
       " 'preferred',\n",
       " 'skills',\n",
       " 'familiarity',\n",
       " 'cloud',\n",
       " 'platforms',\n",
       " 'aws',\n",
       " 'gcp',\n",
       " 'azure',\n",
       " 'knowledge',\n",
       " 'containerization',\n",
       " 'orchestration',\n",
       " 'tools',\n",
       " 'docker',\n",
       " 'kubernetes',\n",
       " 'experience',\n",
       " 'building',\n",
       " 'endtoend',\n",
       " 'ml',\n",
       " 'pipelines',\n",
       " 'strong',\n",
       " 'problemsolving',\n",
       " 'criticalthinking',\n",
       " 'skills',\n",
       " 'excellent',\n",
       " 'communication',\n",
       " 'collaboration',\n",
       " 'abilities',\n",
       " 'benefits',\n",
       " 'competitive',\n",
       " 'salary',\n",
       " 'performancebased',\n",
       " 'bonuses',\n",
       " 'comprehensive',\n",
       " 'health',\n",
       " 'dental',\n",
       " 'vision',\n",
       " 'insurance',\n",
       " 'flexible',\n",
       " 'working',\n",
       " 'hours',\n",
       " 'option',\n",
       " 'remote',\n",
       " 'work',\n",
       " 'professional',\n",
       " 'development',\n",
       " 'opportunities',\n",
       " 'conference',\n",
       " 'attendance',\n",
       " 'collaborative',\n",
       " 'innovative',\n",
       " 'work',\n",
       " 'environment',\n",
       " 'passionate',\n",
       " 'pushing',\n",
       " 'boundaries',\n",
       " 'nlp',\n",
       " 'eager',\n",
       " 'contribute',\n",
       " 'groundbreaking',\n",
       " 'projects',\n",
       " 'invite',\n",
       " 'join',\n",
       " 'team',\n",
       " 'innovative',\n",
       " 'solutions',\n",
       " 'co',\n",
       " 'apply',\n",
       " 'today',\n",
       " 'part',\n",
       " 'shaping',\n",
       " 'future',\n",
       " 'artificial',\n",
       " 'intelligence']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXTRACTING TEXT FROM RESUME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page_number in range(doc.page_count):\n",
    "        page = doc[page_number]\n",
    "        text += page.get_text()\n",
    "    return text\n",
    "\n",
    "# Example usage\n",
    "pdf_path = \"Sudhanwa_Bokade_ML_Resume.pdf\"\n",
    "resume_content = extract_text_from_pdf(pdf_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLEANING THE RESUME CONTENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_content=removing_special_characters(resume_content)\n",
    "resume_content=to_lowercase(resume_content)\n",
    "resume_content=removing_stopwords(resume_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sudhanwa',\n",
       " 'bokade',\n",
       " '91',\n",
       " '9403458774',\n",
       " 'linkedin',\n",
       " 'sudhanwaofficialgmailcom',\n",
       " 'github',\n",
       " 'education',\n",
       " 'vellore',\n",
       " 'institute',\n",
       " 'technology',\n",
       " 'sep',\n",
       " '2020',\n",
       " 'sep',\n",
       " '2024',\n",
       " 'bachelor',\n",
       " 'technology',\n",
       " 'computer',\n",
       " 'science',\n",
       " 'engineering',\n",
       " 'specialization',\n",
       " 'aiml',\n",
       " 'bhopal',\n",
       " 'indore',\n",
       " 'indian',\n",
       " 'institute',\n",
       " 'technology',\n",
       " 'madras',\n",
       " 'sep',\n",
       " '2020',\n",
       " 'oct',\n",
       " '2025',\n",
       " 'bachelor',\n",
       " 'sciencebs',\n",
       " 'degree',\n",
       " 'data',\n",
       " 'science',\n",
       " 'applications',\n",
       " 'chennai',\n",
       " 'tamil',\n",
       " 'nadu',\n",
       " 'technical',\n",
       " 'skills',\n",
       " 'technical',\n",
       " 'skills',\n",
       " 'cc',\n",
       " 'python',\n",
       " 'numpy',\n",
       " 'pandas',\n",
       " 'tensorflow',\n",
       " 'java',\n",
       " 'flask',\n",
       " 'certifications',\n",
       " 'fundamentals',\n",
       " 'data',\n",
       " 'analytics',\n",
       " 'nasscom',\n",
       " 'future',\n",
       " 'skills',\n",
       " 'prime',\n",
       " 'aws',\n",
       " 'certified',\n",
       " 'cloud',\n",
       " 'practitioner',\n",
       " 'courses',\n",
       " 'foundational',\n",
       " 'level',\n",
       " 'programming',\n",
       " 'data',\n",
       " 'science',\n",
       " 'iit',\n",
       " 'madras',\n",
       " 'experience',\n",
       " 'armament',\n",
       " 'research',\n",
       " 'development',\n",
       " 'establishment',\n",
       " 'drdo',\n",
       " 'jul',\n",
       " '2022',\n",
       " 'oct',\n",
       " '2022',\n",
       " 'research',\n",
       " 'intern',\n",
       " 'pune',\n",
       " 'maharashtra',\n",
       " 'gathered',\n",
       " 'audio',\n",
       " 'data',\n",
       " 'utilizing',\n",
       " '2',\n",
       " 'l1s331hh',\n",
       " 'robotic',\n",
       " 'sensors',\n",
       " 'conjunction',\n",
       " 'beagle',\n",
       " 'bone',\n",
       " 'processor',\n",
       " 'demonstrating',\n",
       " 'proficient',\n",
       " 'technical',\n",
       " 'skills',\n",
       " 'data',\n",
       " 'collection',\n",
       " 'assessed',\n",
       " 'cautious',\n",
       " 'data',\n",
       " 'augmentation',\n",
       " 'techniques',\n",
       " 'generate',\n",
       " '50000',\n",
       " 'samples',\n",
       " 'performed',\n",
       " 'exploratory',\n",
       " 'data',\n",
       " 'analysis',\n",
       " 'eda',\n",
       " 'visualize',\n",
       " 'results',\n",
       " 'implemented',\n",
       " '1dcnn',\n",
       " 'deep',\n",
       " 'learning',\n",
       " 'models',\n",
       " 'clean',\n",
       " 'classify',\n",
       " 'audio',\n",
       " 'samples',\n",
       " 'military',\n",
       " 'applications',\n",
       " 'accuracy',\n",
       " '87',\n",
       " 'within',\n",
       " 'less',\n",
       " '80',\n",
       " 'epochs',\n",
       " 'iassist',\n",
       " 'innovation',\n",
       " 'labs',\n",
       " 'iail',\n",
       " 'dec',\n",
       " '2022',\n",
       " 'feb',\n",
       " '2023',\n",
       " 'ai',\n",
       " 'intern',\n",
       " 'remote',\n",
       " 'developed',\n",
       " 'python',\n",
       " 'based',\n",
       " 'optical',\n",
       " 'character',\n",
       " 'recognition',\n",
       " 'ocr',\n",
       " 'script',\n",
       " 'identify',\n",
       " 'extract',\n",
       " 'relevant',\n",
       " 'data',\n",
       " 'discharge',\n",
       " 'summaries',\n",
       " 'medical',\n",
       " 'reports',\n",
       " 'using',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " 'nlp',\n",
       " 'computer',\n",
       " 'vision',\n",
       " 'techniques',\n",
       " 'improved',\n",
       " 'models',\n",
       " 'accuracy',\n",
       " '825',\n",
       " 'projects',\n",
       " 'moodmate',\n",
       " 'python',\n",
       " 'htmlcss',\n",
       " 'flask',\n",
       " 'sqlitetensorflow',\n",
       " 'pytorch',\n",
       " 'apr',\n",
       " '2023',\n",
       " 'spearheaded',\n",
       " 'application',\n",
       " 'training',\n",
       " 'deep',\n",
       " 'learning',\n",
       " 'mode',\n",
       " 'carefully',\n",
       " 'analyzing',\n",
       " 'comprehensive',\n",
       " 'data',\n",
       " '30000',\n",
       " 'samples',\n",
       " 'detecting',\n",
       " 'mood',\n",
       " 'based',\n",
       " 'speech',\n",
       " 'input',\n",
       " 'achieving',\n",
       " 'impressive',\n",
       " 'accuracy',\n",
       " 'rate',\n",
       " 'exceeding',\n",
       " '90',\n",
       " 'assists',\n",
       " 'users',\n",
       " 'personalized',\n",
       " 'historical',\n",
       " 'mood',\n",
       " 'overviews',\n",
       " 'tailored',\n",
       " 'suggestions',\n",
       " 'enhancing',\n",
       " 'wellbeing',\n",
       " 'resulting',\n",
       " 'remarkable',\n",
       " '40',\n",
       " 'increase',\n",
       " 'user',\n",
       " 'satisfaction',\n",
       " '25',\n",
       " 'reduction',\n",
       " 'stress',\n",
       " 'levels',\n",
       " 'remeaitree',\n",
       " 'python',\n",
       " 'reactjs',\n",
       " 'fastapi',\n",
       " 'postgresqlrender',\n",
       " 'tensorflow',\n",
       " 'pytorch',\n",
       " 'feb',\n",
       " '2023',\n",
       " 'contributed',\n",
       " 'project',\n",
       " 'developing',\n",
       " 'ai',\n",
       " 'powered',\n",
       " 'healthcare',\n",
       " 'application',\n",
       " 'incorporating',\n",
       " '30',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'models',\n",
       " 'accuracy',\n",
       " '85',\n",
       " 'accurate',\n",
       " 'disease',\n",
       " 'forecasting',\n",
       " 'diagnosis',\n",
       " 'facilitated',\n",
       " 'access',\n",
       " 'comprehensive',\n",
       " 'health',\n",
       " 'records',\n",
       " 'seamlessly',\n",
       " 'leveraging',\n",
       " 'aisupported',\n",
       " 'diagnostics',\n",
       " 'tailored',\n",
       " 'treatment',\n",
       " 'options',\n",
       " 'remote',\n",
       " 'consultations',\n",
       " 'healthcare',\n",
       " 'professionals',\n",
       " 'rpaislate',\n",
       " 'python',\n",
       " 'htmlcss',\n",
       " 'javascript',\n",
       " 'flask',\n",
       " 'raspberry',\n",
       " 'pi',\n",
       " 'jul',\n",
       " '2022',\n",
       " 'modernized',\n",
       " 'effective',\n",
       " 'learning',\n",
       " 'redesigning',\n",
       " 'costeffective',\n",
       " 'architecture',\n",
       " '50',\n",
       " 'incorporating',\n",
       " 'dual',\n",
       " 'projectors',\n",
       " 'enhance',\n",
       " 'teachinglearning',\n",
       " 'experience',\n",
       " 'proving',\n",
       " '70',\n",
       " 'economical',\n",
       " 'competitors',\n",
       " 'implemented',\n",
       " 'system',\n",
       " 'enabling',\n",
       " 'transfer',\n",
       " 'files',\n",
       " 'wireless',\n",
       " 'manner',\n",
       " 'without',\n",
       " 'internet',\n",
       " 'improving',\n",
       " 'user',\n",
       " 'convenience',\n",
       " '60',\n",
       " 'constructed',\n",
       " 'offline',\n",
       " 'website',\n",
       " 'students',\n",
       " 'access',\n",
       " 'shared',\n",
       " 'study',\n",
       " 'materials',\n",
       " 'automatic',\n",
       " 'attendance',\n",
       " 'takeratt',\n",
       " 'python',\n",
       " 'tensorflow',\n",
       " 'pytorch',\n",
       " 'numpy',\n",
       " 'pandas',\n",
       " 'apr',\n",
       " '2022',\n",
       " 'engineered',\n",
       " 'attendance',\n",
       " 'taking',\n",
       " 'application',\n",
       " 'employing',\n",
       " 'yolov5',\n",
       " 'algorithm',\n",
       " 'automated',\n",
       " 'process',\n",
       " 'taking',\n",
       " 'marking',\n",
       " 'attendance',\n",
       " 'using',\n",
       " 'face',\n",
       " 'recognition',\n",
       " 'accuracy',\n",
       " '90',\n",
       " 'executed',\n",
       " 'feature',\n",
       " 'provides',\n",
       " 'ondemand',\n",
       " 'summary',\n",
       " 'students',\n",
       " 'datewise',\n",
       " 'attendance',\n",
       " 'information',\n",
       " 'specific',\n",
       " 'subject',\n",
       " 'reducing',\n",
       " 'arduous',\n",
       " 'manual',\n",
       " 'work',\n",
       " '50',\n",
       " 'achievements',\n",
       " 'winner',\n",
       " 'smart',\n",
       " 'india',\n",
       " 'hackathon',\n",
       " 'sih',\n",
       " 'held',\n",
       " 'ministry',\n",
       " 'educations',\n",
       " 'moe',\n",
       " 'innovation',\n",
       " 'cell',\n",
       " 'ps',\n",
       " 'id',\n",
       " 'ak',\n",
       " '1091',\n",
       " 'winner',\n",
       " 'hackexchange',\n",
       " 'hackathon',\n",
       " 'held',\n",
       " 'ai',\n",
       " 'club',\n",
       " 'vit',\n",
       " 'bhopal',\n",
       " 'volunteer',\n",
       " 'experience',\n",
       " 'mozilla',\n",
       " 'firefox',\n",
       " 'club',\n",
       " 'nov',\n",
       " '2021',\n",
       " 'nov',\n",
       " '2022',\n",
       " 'technical',\n",
       " 'team',\n",
       " 'member',\n",
       " 'vit',\n",
       " 'bhopal',\n",
       " 'coordinated',\n",
       " 'dedicated',\n",
       " 'technical',\n",
       " 'team',\n",
       " 'member',\n",
       " 'mozilla',\n",
       " 'firefox',\n",
       " 'club',\n",
       " 'vit',\n",
       " 'bhopal',\n",
       " 'organized',\n",
       " 'event',\n",
       " 'experienced',\n",
       " '15',\n",
       " 'lakh',\n",
       " 'views',\n",
       " '700',\n",
       " 'registrations',\n",
       " 'achieved',\n",
       " 'title',\n",
       " 'unstop',\n",
       " 'featured',\n",
       " 'top',\n",
       " 'event']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "METHOD 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_resume_to_job_description(resume_content, job_description):\n",
    "    # Split the job description into keywords\n",
    "\n",
    "    # Count the number of job description keywords that appear in the resume\n",
    "    num_matching_keywords = 0\n",
    "    for keyword in job_description:\n",
    "        if keyword in resume_content:\n",
    "            num_matching_keywords += 1\n",
    "\n",
    "    # Calculate a similarity score between the resume and the job description\n",
    "    similarity_score = num_matching_keywords / len(job_description)\n",
    "\n",
    "    # Return the similarity score\n",
    "    return similarity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_suitability_score(resume_content, job_description):\n",
    "    similarity_score = compare_resume_to_job_description(resume_content, job_description)\n",
    "\n",
    "    # Calculate a suitability score based on the similarity score\n",
    "    suitability_score = similarity_score * 100\n",
    "\n",
    "    # Return the suitability score\n",
    "    return suitability_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.896551724137932\n"
     ]
    }
   ],
   "source": [
    "similarity_score = compare_resume_to_job_description(resume_content, job_description)\n",
    "\n",
    "# Calculate a suitability score for the resume\n",
    "suitability_score = calculate_suitability_score(resume_content, job_description)\n",
    "\n",
    "# Print the suitability score\n",
    "print(suitability_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "METHOD 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_key_terms(job_description):\n",
    "    # Tokenize the job description\n",
    "    tokens = word_tokenize(job_description)\n",
    "\n",
    "    # Part-of-speech tagging using NLTK\n",
    "    tagged_tokens = pos_tag(tokens)\n",
    "\n",
    "    # Extract nouns and adjectives as key terms\n",
    "    key_terms = [word for word, pos in tagged_tokens if pos in ['NN', 'NNS', 'JJ']]\n",
    "\n",
    "    return key_terms\n",
    "\n",
    "def extract_skills_and_requirements(job_description):\n",
    "    # Process the job description using spaCy\n",
    "    doc = nlp(job_description)\n",
    "\n",
    "    # Extract entities (skills and requirements)\n",
    "    skills_requirements = [ent.text for ent in doc.ents if ent.label_ in ['ORG', 'PERSON', 'GPE']]\n",
    "\n",
    "    return skills_requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key Terms: ['job', 'title', 'machine', 'engineer', 'nlp', 'location', 'usa', 'company', 'innovative', 'solutions', 'innovative', 'solutions', 'cuttingedge', 'technology', 'company', 'artificial', 'intelligence', 'revolution', 'intelligent', 'systems', 'leverage', 'machine', 'deep', 'learning', 'nlp', 'solve', 'complex', 'problems', 'user', 'experiences', 'job', 'description', 'machine', 'engineer', 'natural', 'language', 'processing', 'innovative', 'solutions', 'pivotal', 'role', 'advanced', 'nlp', 'models', 'solutions', 'collaborative', 'dynamic', 'environment', 'boundaries', 'whats', 'possible', 'ai', 'technologies', 'responsibilities', 'research', 'design', 'implement', 'stateoftheart', 'nlp', 'algorithms', 'models', 'scalable', 'efficient', 'solutions', 'language', 'understanding', 'collaborate', 'crossfunctional', 'teams', 'nlp', 'capabilities', 'products', 'advancements', 'nlp', 'machine', 'research', 'optimize', 'finetune', 'models', 'performance', 'work', 'realworld', 'information', 'retrieval', 'sentiment', 'analysis', 'language', 'generation', 'qualifications', 'masters', 'computer', 'science', 'machine', 'related', 'field', 'solid', 'foundation', 'machine', 'deep', 'learning', 'principles', 'experience', 'nlp', 'solutions', 'proficiency', 'languages', 'pytorch', 'strong', 'understanding', 'neural', 'network', 'architectures', 'attention', 'mechanisms', 'largescale', 'data', 'processing', 'preferred', 'skills', 'familiarity', 'platforms', 'gcp', 'azure', 'knowledge', 'containerization', 'orchestration', 'tools', 'docker', 'experience', 'ml', 'pipelines', 'strong', 'skills', 'excellent', 'communication', 'collaboration', 'benefits', 'competitive', 'salary', 'bonuses', 'comprehensive', 'health', 'dental', 'vision', 'insurance', 'flexible', 'working', 'hours', 'option', 'work', 'professional', 'development', 'opportunities', 'conference', 'attendance', 'collaborative', 'innovative', 'work', 'environment', 'passionate', 'boundaries', 'eager', 'contribute', 'projects', 'invite', 'join', 'team', 'innovative', 'solutions', 'today', 'part', 'future', 'artificial', 'intelligence', 'phd']\n",
      "Skills and Requirements: ['phd']\n"
     ]
    }
   ],
   "source": [
    "result_string = ' '.join(job_description)\n",
    "key_terms_job_description = extract_key_terms(result_string)\n",
    "print(\"Key Terms:\", key_terms)\n",
    "\n",
    "# Extract skills and requirements\n",
    "skills_requirements_job_description = extract_skills_and_requirements(result_string)\n",
    "print(\"Skills and Requirements:\", skills_requirements_job_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key Terms: ['sudhanwa', 'linkedin', 'sudhanwaofficialgmailcom', 'github', 'education', 'institute', 'technology', 'sep', 'sep', 'bachelor', 'technology', 'computer', 'science', 'engineering', 'specialization', 'aiml', 'bhopal', 'indore', 'indian', 'institute', 'technology', 'madras', 'bachelor', 'degree', 'data', 'science', 'applications', 'tamil', 'nadu', 'technical', 'skills', 'technical', 'skills', 'python', 'numpy', 'pandas', 'tensorflow', 'java', 'flask', 'certifications', 'fundamentals', 'data', 'analytics', 'nasscom', 'future', 'skills', 'prime', 'aws', 'cloud', 'practitioner', 'courses', 'foundational', 'level', 'data', 'science', 'iit', 'madras', 'experience', 'armament', 'research', 'development', 'establishment', 'drdo', 'jul', 'oct', 'research', 'intern', 'pune', 'maharashtra', 'audio', 'data', 'l1s331hh', 'robotic', 'sensors', 'bone', 'processor', 'proficient', 'technical', 'skills', 'data', 'collection', 'cautious', 'data', 'augmentation', 'techniques', 'samples', 'exploratory', 'data', 'analysis', 'eda', 'visualize', 'results', 'deep', 'learning', 'models', 'classify', 'audio', 'samples', 'military', 'applications', 'epochs', 'iassist', 'innovation', 'labs', 'dec', 'feb', 'ai', 'intern', 'remote', 'python', 'optical', 'character', 'recognition', 'script', 'identify', 'extract', 'relevant', 'data', 'discharge', 'summaries', 'medical', 'reports', 'natural', 'language', 'processing', 'nlp', 'computer', 'vision', 'techniques', 'models', 'projects', 'python', 'sqlitetensorflow', 'pytorch', 'apr', 'application', 'training', 'deep', 'learning', 'mode', 'comprehensive', 'data', 'samples', 'mood', 'speech', 'input', 'impressive', 'accuracy', 'rate', 'assists', 'users', 'historical', 'mood', 'overviews', 'suggestions', 'remarkable', 'increase', 'user', 'satisfaction', 'reduction', 'stress', 'levels', 'python', 'reactjs', 'fastapi', 'postgresqlrender', 'pytorch', 'feb', 'project', 'ai', 'healthcare', 'application', 'machine', 'learning', 'models', 'accurate', 'disease', 'diagnosis', 'access', 'comprehensive', 'health', 'records', 'diagnostics', 'treatment', 'options', 'consultations', 'professionals', 'python', 'htmlcss', 'javascript', 'flask', 'raspberry', 'pi', 'jul', 'effective', 'learning', 'costeffective', 'architecture', 'dual', 'projectors', 'experience', 'economical', 'competitors', 'system', 'transfer', 'files', 'manner', 'internet', 'user', 'convenience', 'offline', 'website', 'students', 'access', 'study', 'materials', 'automatic', 'attendance', 'takeratt', 'python', 'pytorch', 'numpy', 'pandas', 'apr', 'attendance', 'application', 'process', 'attendance', 'face', 'recognition', 'accuracy', 'executed', 'feature', 'summary', 'students', 'attendance', 'information', 'specific', 'subject', 'arduous', 'manual', 'work', 'achievements', 'winner', 'smart', 'india', 'hackathon', 'ministry', 'educations', 'innovation', 'cell', 'id', 'ak', 'winner', 'hackexchange', 'club', 'vit', 'bhopal', 'volunteer', 'experience', 'mozilla', 'firefox', 'club', 'nov', 'nov', 'technical', 'team', 'member', 'vit', 'bhopal', 'dedicated', 'technical', 'team', 'member', 'mozilla', 'firefox', 'club', 'vit', 'bhopal', 'event', 'lakh', 'views', 'registrations', 'title', 'unstop', 'top', 'event']\n",
      "Skills and Requirements: ['github education vellore institute technology', 'iit madras', 'drdo jul', 'pune maharashtra', 'attendance takeratt', 'numpy pandas', 'india', 'ps id ak 1091', 'vit', 'vit', 'vit']\n"
     ]
    }
   ],
   "source": [
    "result_string_resume = ' '.join(resume_content)\n",
    "key_terms_resume = extract_key_terms(result_string_resume)\n",
    "print(\"Key Terms:\", key_terms_resume)\n",
    "\n",
    "# Extract skills and requirements\n",
    "skills_requirements_resume = extract_skills_and_requirements(result_string_resume)\n",
    "print(\"Skills and Requirements:\", skills_requirements_resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_terms_resume.extend(skills_requirements_resume)\n",
    "key_terms_job_description.extend(skills_requirements_job_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.28571428571429\n"
     ]
    }
   ],
   "source": [
    "similarity_score = compare_resume_to_job_description(key_terms_resume, key_terms_job_description)\n",
    "\n",
    "# Calculate a suitability score for the resume\n",
    "suitability_score = calculate_suitability_score(key_terms_resume, key_terms_job_description)\n",
    "\n",
    "# Print the suitability score\n",
    "print(suitability_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
